---
title: "Datenwissenschaft in der Bildungsforschung"
subtitle: "Week 7 - Validity"
author: "Job Schepens"
institute: "IFS, TU Dortmund"
date: "`r Sys.Date()`"
output:
  xaringan::moon_reader:
    lib_dir: libs
    css: "../slides.css"
    nature:
      highlightLines: true
      highlightStyle: solarized-light
      countIncrementalSlides: false
---

```{r child = "../setup.Rmd"}
```

## Topics

- Discuss homework
- Discuss readings

---


## This week's assignment

- Open education data resources
	- Newsletter Deutscher Bildungs Server
		- [DBS - Bildungsforschung](https://www.bildungsserver.de/onlineressourcen.html?fach=4440)
	- Large studies
		- [TIMMS](https://timssandpirls.bc.edu/timss2015/international-database/)
		- [PISA](https://rdrr.io/cran/EdSurvey/man/readPISA.html)
	- Data that goes along with books
		- [Estrellado et al. (2020). Dataedu.](https://github.com/data-edu/dataedu/tree/master/inst/extdata)
	- Kaggle  
		- [e.g. student performance](https://www.kaggle.com/renaudgendron/eda-student-performance)
	- Public institutions and governments
		- [OECD](https://www.oecd.org/education/database.htm)

---


## What is validity?

- Are we measuring what we want to measure?
	- e.g. self-concept, attitudes, learning
- Content and face validity
	- "My teachers always try to help me" attitude to school vs teacher
- Criterion validity
	- predictive validity: 
		- does the instrument predict expected outcomes
		- e.g: do entry scores predict successful course completion
	- concurrent validity
		- do scores agree with related scores
- Construct validity
	- a measure of x should not measure y and/or z
	- check using factor analysis
	
---


## What is reliability?

- Score = True score + Systematic error + Random error
	- systematic error 
		- bias or calibration error 
		- reduces validity
		- instrument design
	- random error reduces reliability
		- research design
- Repeated measurement
	- test-retest > .8 
	- carryover
	- inter-rater reliability
- Internal consistency
	- split half reliability > .8
	- alpha 
- Narrow is more reliable, broad is more valid

---


## Generalisability

- p-value
	- What is the probability that a relationship in our sample that does not exist in the population? 
- Type I (no real relation) and Type II error (missed real relation)
- Conservative approach
	- focus on disproving the null hypothesis / minimizing type 1 errors
- P value depends on effect size and sample size
- Confidence intervals (CI) and effect sizes bypass problems with H0 and p-value threshold
- CI95
	- given x in our sample, the probability that x in the population is somewhere between a minimum and a maximum value is 95%
	
---


## Discussion points

1. What can you do to make your instrument more valid?
2. What do you think about the effect size vs. significance test debate:
should we stick with significance levels, or replace them by effect size
indices and confidence intervals?
3. How would you calculate whether or not your test was reliable?
4. Do you think a more reliable test is automatically more valid?
5. What types of error can you make when accepting the alternative
hypothesis?
6. How can you make your instruments more reliable?

---


## Next week: 

- Read Praxis chapter
- Get familiar with data